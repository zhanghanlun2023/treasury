
import os
import warnings
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

import streamlit as st
import plotly.graph_objs as go

warnings.filterwarnings("ignore")

# ============================================================
# ä¸€ã€UI ä¸»é¢˜ï¼šè“é‡‘é…è‰² + å¡ç‰‡æ ·å¼ï¼ˆåŸºç¡€æ ·å¼ï¼Œæš—é»‘æ¨¡å¼ä¸‹å±€éƒ¨è¦†ç›–ï¼‰
# ============================================================

BLUE = "#0055A4"
GOLD = "#CFAF70"
BG_LIGHT = "#F5F7FA"

BASE_CSS = f"""
<style>
body {{
    background-color: {BG_LIGHT};
}}
h1 {{
    color: {BLUE} !important;
    font-weight: 900 !important;
}}
h2, h3, h4 {{
    color: {BLUE} !important;
}}
.big-number {{
    font-size: 32px;
    font-weight: 700;
    color: {BLUE};
    text-align: center;
}}
.big-number-gold {{
    font-size: 32px;
    font-weight: 700;
    color: {GOLD};
    text-align: center;
}}
.card {{
    background-color: white;
    padding: 16px;
    border-radius: 12px;
    border: 1px solid #E0E4EA;
    box-shadow: 0 2px 8px rgba(0,0,0,0.05);
}}
.card-title {{
    font-size: 14px;
    color: #666;
    text-align: center;
    margin-top: 8px;
}}
.card-sub {{
    font-size: 12px;
    color: #999;
    text-align: center;
}}
</style>
"""

st.markdown(BASE_CSS, unsafe_allow_html=True)


# ============================================================
# äºŒã€åˆ—åæ˜ å°„ï¼ˆè‹±æ–‡ â†’ ä¸­æ–‡ï¼‰
# ============================================================

COLUMN_NAME_MAP = {
    "date": "æ—¥æœŸ",
    "cash_in": "ç°é‡‘æµå…¥",
    "cash_out": "ç°é‡‘æµå‡º",
    "net_cash_flow": "å‡€ç°é‡‘æµ",
    "sales": "é”€å”®æ”¶å…¥",
    "project_spend": "é¡¹ç›®æ”¯å‡º",
    "tax_payment": "ç¨è´¹ç¼´çº³",
}

FEATURE_NAME_MAP = COLUMN_NAME_MAP


def format_date_series(s: pd.Series) -> pd.Series:
    return pd.to_datetime(s).dt.strftime("%Y-%m-%d")


def styled_table(df: pd.DataFrame):
    if df.empty:
        return df.style

    df2 = df.copy()
    if "æ—¥æœŸ" in df2.columns:
        df2["æ—¥æœŸ"] = format_date_series(df2["æ—¥æœŸ"])

    numeric_cols = df2.select_dtypes(include=[np.number]).columns

    styler = df2.style
    if len(numeric_cols) > 0:
        styler = styler.format("{:.2f}", subset=numeric_cols)
        styler = styler.set_properties(**{"text-align": "center"}, subset=numeric_cols)

    return styler


# ============================================================
# ä¸‰ã€æ•°æ®ç”Ÿæˆ & é¢„å¤„ç†
# ============================================================

def generate_synthetic_data(n_days: int = 730) -> pd.DataFrame:
    start_date = datetime(2023, 1, 1)
    dates = [start_date + timedelta(days=i) for i in range(n_days)]
    t = np.arange(n_days)

    sales = (
        200000 + 500 * t +
        50000 * np.sin(2 * np.pi * t / 365) +
        20000 * np.random.randn(n_days)
    )

    project_spend = (
        80000 + 10000 * np.sin(2 * np.pi * t / 180) +
        15000 * np.random.randn(n_days)
    )

    spikes = np.random.choice(n_days, size=15, replace=False)
    project_spend[spikes] += np.random.uniform(50000, 200000, len(spikes))

    tax_payment = np.zeros(n_days)
    for i, d in enumerate(dates):
        if d.day == 15:
            tax_payment[i] = 50000 + 20000 * np.random.rand()

    cash_in = sales * np.random.uniform(0.7, 0.9) + np.random.randn(n_days) * 20000
    cash_out = project_spend + tax_payment + np.random.uniform(0.4, 0.6) * 0.5 * sales

    df = pd.DataFrame({
        "date": dates,
        "cash_in": cash_in,
        "cash_out": cash_out,
        "sales": sales,
        "project_spend": project_spend,
        "tax_payment": tax_payment
    })
    df["net_cash_flow"] = df["cash_in"] - df["cash_out"]

    return df


def basic_preprocess(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["date"] = pd.to_datetime(df["date"])
    df = df.sort_values("date")

    df = df.set_index("date")
    full_range = pd.date_range(df.index.min(), df.index.max(), freq="D")
    df = df.reindex(full_range)
    df.index.name = "date"
    df = df.reset_index()

    num_cols = df.select_dtypes(include=[np.number]).columns
    df[num_cols] = df[num_cols].interpolate().ffill().bfill()

    return df


def load_data_from_upload(uploaded_file) -> pd.DataFrame:
    df = pd.read_csv(uploaded_file)

    if "date" not in df.columns:
        raise ValueError("CSV å¿…é¡»åŒ…å« date åˆ—")

    if "net_cash_flow" not in df.columns:
        if "cash_in" in df.columns and "cash_out" in df.columns:
            df["net_cash_flow"] = df["cash_in"] - df["cash_out"]
        else:
            raise ValueError("ç¼ºå°‘ net_cash_flow ä¸”æ— æ³•è‡ªåŠ¨ç”Ÿæˆ")

    return basic_preprocess(df).dropna().reset_index(drop=True)


# ============================================================
# å››ã€LSTM ç›¸å…³å‡½æ•°
# ============================================================

def create_sequences(X, y, window_size=60):
    xs, ys = [], []
    for i in range(len(X) - window_size):
        xs.append(X[i:i + window_size])
        ys.append(y[i + window_size])
    return np.array(xs), np.array(ys)


def build_lstm_model(input_shape):
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout

    model = Sequential()
    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(LSTM(32))
    model.add(Dropout(0.2))
    model.add(Dense(1))

    model.compile(loss="mse", optimizer="adam")
    return model


def train_lstm_model(df, feature_cols, target="net_cash_flow",
                     window=60, epochs=20, batch_size=32):

    feature_cols = list(dict.fromkeys(feature_cols))
    X_raw = df[feature_cols].astype(float).values
    y_raw = df[[target]].astype(float).values.reshape(-1, 1)

    fs = MinMaxScaler()
    ts = MinMaxScaler()

    X_scaled = fs.fit_transform(X_raw)
    y_scaled = ts.fit_transform(y_raw)

    X_seq, y_seq = create_sequences(X_scaled, y_scaled, window)

    if len(X_seq) < 10:
        raise ValueError("æ ·æœ¬é‡è¿‡å°‘ï¼Œæ— æ³•è®­ç»ƒ LSTM æ¨¡å‹ï¼Œè¯·æä¾›æ›´å¤šæ•°æ®ã€‚")

    split = int(len(X_seq) * 0.8)
    X_train, X_val = X_seq[:split], X_seq[split:]
    y_train, y_val = y_seq[:split], y_seq[split:]

    model = build_lstm_model((window, X_seq.shape[2]))

    from tensorflow.keras.callbacks import EarlyStopping
    es = EarlyStopping(patience=5, restore_best_weights=True)

    model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=epochs,
        batch_size=batch_size,
        callbacks=[es],
        verbose=0
    )

    pred_scaled = model.predict(X_val, verbose=0)
    y_true = ts.inverse_transform(y_val).reshape(-1)
    y_pred = ts.inverse_transform(pred_scaled).reshape(-1)

    mae = float(np.mean(np.abs(y_true - y_pred)))
    rmse = float(np.sqrt(np.mean((y_true - y_pred) ** 2)))

    hist_df = df[["date", target]].copy()

    return model, fs, ts, X_scaled, y_scaled, hist_df, {"mae": mae, "rmse": rmse}


# ============================================================
# äº”ã€MC Dropout å¤šæ­¥é¢„æµ‹
# ============================================================

def mc_dropout_forecast_batch(model,
                              last_window,
                              scaler,
                              steps=60,
                              n_samples=30):
    means, stds = [], []
    cur = last_window.copy()

    for _ in range(steps):
        batch = np.repeat(cur[np.newaxis], n_samples, axis=0)
        preds = model(batch, training=True).numpy().reshape(-1)

        mu = preds.mean()
        sigma = preds.std(ddof=1) if len(preds) > 1 else 0.0

        means.append(mu)
        stds.append(sigma)

        nxt = cur[-1].copy()
        nxt[0] = mu
        cur = np.vstack([cur[1:], nxt])

    means = np.array(means).reshape(-1, 1)
    stds = np.array(stds).reshape(-1, 1)

    upper = means + 1.96 * stds
    lower = means - 1.96 * stds

    return (
        scaler.inverse_transform(means).reshape(-1),
        scaler.inverse_transform(lower).reshape(-1),
        scaler.inverse_transform(upper).reshape(-1)
    )


# ============================================================
# å…­ã€å¼‚å¸¸æ£€æµ‹ & æ•æ„Ÿæ€§åˆ†æ
# ============================================================

def detect_anomalies_combined(dates, values, z_thresh=3.0, iqr_k=1.5):
    v = np.asarray(values, float).reshape(-1)
    d = np.asarray(dates)

    mu = float(v.mean())
    sigma = float(v.std(ddof=1))
    z = np.zeros_like(v) if sigma == 0 else (v - mu) / sigma
    z_mask = (np.abs(z) >= z_thresh).reshape(-1)

    Q1, Q3 = np.percentile(v, 25), np.percentile(v, 75)
    IQR = Q3 - Q1
    low, high = Q1 - iqr_k * IQR, Q3 + iqr_k * IQR
    iqr_mask = ((v < low) | (v > high)).reshape(-1)

    mask = (z_mask | iqr_mask).reshape(-1)

    if not mask.any():
        return pd.DataFrame()

    severity = np.abs(z) / max(z_thresh, 1e-6) + iqr_mask.astype(float)

    df = pd.DataFrame({
        "date": d[mask],
        "value": v[mask],
        "zscore": z[mask],
        "iqr_flag": iqr_mask[mask],
        "z_flag": z_mask[mask],
        "severity": severity[mask]
    })

    return df.sort_values("severity", ascending=False).reset_index(drop=True)


def feature_sensitivity_last_window(model,
                                    window,
                                    feature_names,
                                    scaler,
                                    delta=0.1):
    base_scaled = float(model(window[np.newaxis], training=False).numpy().squeeze())
    base = scaler.inverse_transform([[base_scaled]])[0, 0]

    results = []
    for i, name in enumerate(feature_names):
        pert = window.copy()
        pert[:, i] *= (1 + delta)

        new_scaled = float(model(pert[np.newaxis], training=False).numpy().squeeze())
        new_val = scaler.inverse_transform([[new_scaled]])[0, 0]

        results.append({"feature": name, "change": new_val - base})

    return pd.DataFrame(results).sort_values("change", ascending=False)


def anomalies_to_chinese(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    out = df.copy()
    out.rename(columns={
        "date": "æ—¥æœŸ",
        "value": "å‡€ç°é‡‘æµ",
        "zscore": "Zå€¼",
        "iqr_flag": "IQRå¼‚å¸¸",
        "z_flag": "Zå¼‚å¸¸",
        "severity": "å¼‚å¸¸å¼ºåº¦"
    }, inplace=True)
    out["æ—¥æœŸ"] = format_date_series(out["æ—¥æœŸ"])
    return out


def sensitivity_to_chinese(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    out = df.copy()
    out["feature"] = out["feature"].apply(lambda x: FEATURE_NAME_MAP.get(x, x))
    out.rename(columns={"feature": "ç‰¹å¾", "change": "å½±å“å€¼"}, inplace=True)
    return out


# ============================================================
# ä¸ƒã€Plotly å›¾è¡¨æ„å»ºï¼ˆæ”¯æŒå¤šæ¨¡å¼ï¼‰
# ============================================================

def build_forecast_figure(
    history,
    forecast_df,
    scenario_name,
    viz_mode="æ ‡å‡†æ¨¡å¼",
):
    dates_hist = format_date_series(history["date"])
    dates_fut = forecast_df["æ—¥æœŸ"]
    hist_values = history["net_cash_flow"]

    if viz_mode == "æš—é»‘æ¨¡å¼":
        template = "plotly_dark"
        bg_color = "#0d1117"
        plot_bg = "#0d1117"
        line_hist_color = "#00BFFF"
        line_pred_color = "#8A2BE2"
        band_color = "rgba(0, 191, 255, 0.2)"
        zero_line_color = "#FF4B4B"
    elif viz_mode == "å¸åº“é©¾é©¶èˆ±æ¨¡å¼":
        template = "plotly_white"
        bg_color = "#F2F4F8"
        plot_bg = "white"
        line_hist_color = BLUE
        line_pred_color = GOLD
        band_color = "rgba(0, 85, 164, 0.15)"
        zero_line_color = "red"
    else:  # æ ‡å‡†æ¨¡å¼
        template = "plotly_white"
        bg_color = BG_LIGHT
        plot_bg = "white"
        line_hist_color = BLUE
        line_pred_color = "#FF7F0E"
        band_color = "rgba(0, 85, 164, 0.15)"
        zero_line_color = "red"

    fig = go.Figure()

    # å†å²å‡€ç°é‡‘æµ
    fig.add_trace(
        go.Scatter(
            x=dates_hist,
            y=hist_values,
            mode="lines",
            name="å†å²å‡€ç°é‡‘æµ",
            line=dict(color=line_hist_color, width=2),
            hovertemplate="æ—¥æœŸ=%{x}<br>å‡€ç°é‡‘æµ=%{y:,.2f}<extra></extra>",
        )
    )

    # é¢„æµ‹å‡å€¼
    fig.add_trace(
        go.Scatter(
            x=dates_fut,
            y=forecast_df["é¢„æµ‹å‡å€¼"],
            mode="lines",
            name=f"{scenario_name}æƒ…æ™¯é¢„æµ‹å‡å€¼",
            line=dict(color=line_pred_color, width=2, dash="dash"),
            hovertemplate="æ—¥æœŸ=%{x}<br>é¢„æµ‹å‡€ç°é‡‘æµ=%{y:,.2f}<extra></extra>",
        )
    )

    # ç½®ä¿¡åŒºé—´å¸¦
    fig.add_trace(
        go.Scatter(
            x=dates_fut,
            y=forecast_df["ä¸Šç•Œï¼ˆ95%ï¼‰"],
            mode="lines",
            line=dict(width=0),
            showlegend=False,
            hoverinfo="skip",
        )
    )
    fig.add_trace(
        go.Scatter(
            x=dates_fut,
            y=forecast_df["ä¸‹ç•Œï¼ˆ95%ï¼‰"],
            mode="lines",
            line=dict(width=0),
            fill="tonexty",
            fillcolor=band_color,
            name="95% ç½®ä¿¡åŒºé—´",
            hovertemplate="æ—¥æœŸ=%{x}<br>åŒºé—´=[%{y:,.2f}, %{customdata:,.2f}]<extra></extra>",
            customdata=forecast_df["ä¸Šç•Œï¼ˆ95%ï¼‰"],
        )
    )

    # èµ„é‡‘ç¼ºå£é¢„è­¦çº¢çº¿
    fig.add_hline(
        y=0,
        line_dash="dot",
        line_color=zero_line_color,
        annotation_text="èµ„é‡‘ç¼ºå£é¢„è­¦çº¢çº¿ï¼ˆ0ï¼‰",
        annotation_position="top left",
        annotation_font=dict(color=zero_line_color),
    )

    fig.update_layout(
        template=template,
        paper_bgcolor=bg_color,
        plot_bgcolor=plot_bg,
        margin=dict(l=40, r=20, t=60, b=40),
        xaxis=dict(
            title="æ—¥æœŸ",
            tickangle=-45,
            showgrid=True,
            tickfont=dict(size=10),
        ),
        yaxis=dict(
            title="å‡€ç°é‡‘æµ",
            showgrid=True,
        ),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
        ),
        hovermode="x unified",
        title=dict(
            text=f"ç°é‡‘æµé¢„æµ‹ï¼ˆé›†æˆæ¨¡å‹ + ç½®ä¿¡åŒºé—´ + æƒ…æ™¯ï¼š{scenario_name}ï¼‰",
            x=0.5,
            xanchor="center",
        ),
    )

    return fig


# ============================================================
# å…«ã€Streamlit ä¸»ç¨‹åºï¼ˆæ”¯æŒæ¨¡å¼åˆ‡æ¢ï¼‰
# ============================================================

def main():
    st.set_page_config(page_title="AI èµ‹èƒ½å¸åº“ï¼šç°é‡‘æµé¢„æµ‹ç³»ç»Ÿ", layout="wide")

    # ä¾§è¾¹æ æ¨¡å¼åˆ‡æ¢
    st.sidebar.header("ğŸ› æ˜¾ç¤ºä¸é¢„æµ‹æ¨¡å¼")
    viz_mode = st.sidebar.radio(
        "å¯è§†åŒ–æ¨¡å¼",
        ["æ ‡å‡†æ¨¡å¼", "å¸åº“é©¾é©¶èˆ±æ¨¡å¼", "æš—é»‘æ¨¡å¼"],
        index=0,
        help="å¯åœ¨æ ‡å‡† / å¸åº“é©¾é©¶èˆ± / æš—é»‘å¤§å±ä¸‰ç§æ¨¡å¼é—´åˆ‡æ¢å±•ç¤ºæ•ˆæœã€‚",
    )

    # ä¾§è¾¹æ å‚æ•°
    st.sidebar.header("âš™ å‚æ•°è®¾ç½®")

    uploaded_file = st.sidebar.file_uploader("ğŸ“¤ ä¸Šä¼ ç°é‡‘æµ CSVï¼ˆå« date åˆ—ï¼‰", type=["csv"])
    use_synthetic = st.sidebar.checkbox(
        "ä½¿ç”¨ç³»ç»Ÿæ¨¡æ‹Ÿæ•°æ®ï¼ˆå¿½ç•¥ä¸Šä¼ æ–‡ä»¶ï¼‰",
        value=(uploaded_file is None)
    )

    window_size = st.sidebar.slider("æ—¶é—´çª—å£é•¿åº¦ï¼ˆå¤©ï¼‰", 30, 120, 60, step=5)
    forecast_days = st.sidebar.slider("é¢„æµ‹å¤©æ•°", 7, 180, 90, step=7)
    epochs = st.sidebar.slider("è®­ç»ƒè½®æ•°ï¼ˆEpochï¼‰", 5, 50, 20, step=5)
    n_samples = st.sidebar.slider("Monte-Carlo Dropout æ¬¡æ•°", 10, 100, 30, step=10)

    # æƒ…æ™¯åˆ‡æ¢
    scenario = st.sidebar.radio(
        "æƒ…æ™¯æ¨¡å¼",
        ["è°¨æ…", "ä¸­æ€§", "ä¹è§‚"],
        index=1,
        help="è°¨æ…ï¼šåœ¨é¢„æµ‹åŸºç¡€ä¸Šä¸‹è°ƒ 10%ï¼›ä¹è§‚ï¼šåœ¨é¢„æµ‹åŸºç¡€ä¸Šä¸Šè°ƒ 10%ã€‚"
    )

    run_button = st.sidebar.button("ğŸš€ å¼€å§‹è®­ç»ƒä¸é¢„æµ‹")

    # é¡¶éƒ¨ LOGO + æ ‡é¢˜åŒº
    col_logo, col_title, col_mode = st.columns([1, 4, 2])

    with col_logo:
        logo_path = "logo.png"
        if os.path.exists(logo_path):
            st.image(logo_path, width=80)
        else:
            st.markdown(
                f"<div style='width:80px;height:80px;border-radius:12px;"
                f"background:{BLUE};display:flex;align-items:center;justify-content:center;'>"
                f"<span style='color:white;font-weight:bold;'>LOGO</span></div>",
                unsafe_allow_html=True
            )

    with col_title:
        st.markdown(
            f"""
            <h1>AI èµ‹èƒ½å¸åº“ Â· ç°é‡‘æµé¢„æµ‹ç³»ç»Ÿ</h1>
            <h4 style="color:{GOLD};margin-top:-8px;">ç°ä»£æŠ•èµ„è´¢åŠ¡å¸åº“ç®¡ç†æ¡ˆä¾‹ç³»ç»Ÿ</h4>
            <h5 style="color:#777;margin-top:-12px;">æ¡ˆä¾‹ï¼šAIèµ‹èƒ½å¸åº“å†…éƒ¨èµ„é‡‘ç®¡ç†â€”â€”åŸºäºLSTMçš„ç°é‡‘æµé¢„æµ‹ç³»ç»Ÿ</h5>
            """,
            unsafe_allow_html=True
        )

    with col_mode:
        st.markdown(
            f"""
            <div class="card">
                <div class="card-title">å½“å‰å¯è§†åŒ–æ¨¡å¼</div>
                <div class="big-number-gold">{viz_mode}</div>
                <div class="card-sub">å¯åœ¨å·¦ä¾§åˆ‡æ¢å±•ç¤ºé£æ ¼</div>
            </div>
            """,
            unsafe_allow_html=True
        )

    st.markdown("---")

    # æ•°æ®åŠ è½½
    if use_synthetic:
        df = generate_synthetic_data()
    else:
        if uploaded_file is None:
            st.warning("è¯·ä¸Šä¼  CSV æ–‡ä»¶æˆ–å‹¾é€‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ã€‚")
            return
        try:
            df = load_data_from_upload(uploaded_file)
        except Exception as e:
            st.error(f"æ•°æ®åŠ è½½å¤±è´¥ï¼š{e}")
            return

    df = basic_preprocess(df)

    # =============== å¸åº“é©¾é©¶èˆ±å¤§å±æ¨¡å¼ï¼šé¡¶éƒ¨å¤šæŒ‡æ ‡å¸ƒå±€ ===============
    if viz_mode == "å¸åº“é©¾é©¶èˆ±æ¨¡å¼":
        st.subheader("ğŸ“Š å¸åº“é©¾é©¶èˆ± Â· èµ„é‡‘å…¨æ™¯æ€»è§ˆ")

        last_net_cf = float(df["net_cash_flow"].iloc[-1])
        last30_std = float(df["net_cash_flow"].tail(30).std())
        avg7 = float(df["net_cash_flow"].tail(7).mean())
        max_in = float(df["cash_in"].tail(30).max())
        max_out = float(df["cash_out"].tail(30).max())

        c1, c2, c3, c4 = st.columns(4)
        with c1:
            st.markdown(
                f"""
                <div class="card">
                    <div class="big-number">{last_net_cf:,.2f}</div>
                    <div class="card-title">ä»Šæ—¥å‡€ç°é‡‘æµï¼ˆå…ƒï¼‰</div>
                </div>
                """,
                unsafe_allow_html=True
            )
        with c2:
            st.markdown(
                f"""
                <div class="card">
                    <div class="big-number">{avg7:,.2f}</div>
                    <div class="card-title">è¿‘7æ—¥å¹³å‡å‡€ç°é‡‘æµï¼ˆå…ƒï¼‰</div>
                </div>
                """,
                unsafe_allow_html=True
            )
        with c3:
            st.markdown(
                f"""
                <div class="card">
                    <div class="big-number">{last30_std:,.2f}</div>
                    <div class="card-title">è¿‘30æ—¥å‡€ç°é‡‘æµæ³¢åŠ¨ç‡</div>
                </div>
                """,
                unsafe_allow_html=True
            )
        with c4:
            st.markdown(
                f"""
                <div class="card">
                    <div class="big-number-gold">{max_out:,.2f}</div>
                    <div class="card-title">è¿‘30æ—¥å•æ—¥æœ€å¤§ç°é‡‘æµå‡º</div>
                </div>
                """,
                unsafe_allow_html=True
            )
    else:
        # æ ‡å‡† / æš—é»‘æ¨¡å¼æ²¿ç”¨ä¹‹å‰çš„ Dashboard
        st.subheader("ğŸ“Š èµ„é‡‘ç›‘æ§å¤§å± Dashboard")

        last_net_cf = float(df["net_cash_flow"].iloc[-1])
        last30_std = float(df["net_cash_flow"].tail(30).std())
        avg7 = float(df["net_cash_flow"].tail(7).mean())

        c1, c2, c3 = st.columns(3)
        with c1:
            st.markdown(
                f"""
                <div class="card">
                    <div class="big-number">{last_net_cf:,.2f}</div>
                    <div class="card-title">ä»Šæ—¥å‡€ç°é‡‘æµï¼ˆå…ƒï¼‰</div>
                </div>
                """,
                unsafe_allow_html=True
            )
        with c2:
            st.markdown(
                f"""
                <div class="card">
                    <div class="big-number">{last30_std:,.2f}</div>
                    <div class="card-title">è¿‘30æ—¥å‡€ç°é‡‘æµæ³¢åŠ¨ç‡</div>
                </div>
                """,
                unsafe_allow_html=True
            )
        with c3:
            st.markdown(
                f"""
                <div class="card">
                    <div class="big-number-gold">{avg7:,.2f}</div>
                    <div class="card-title">è¿‘7æ—¥å¹³å‡å‡€ç°é‡‘æµï¼ˆå…ƒï¼‰</div>
                </div>
                """,
                unsafe_allow_html=True
            )

    # AI è§‚ç‚¹
    st.markdown("#### ğŸ’¡ AI å¸åº“è§‚ç‚¹")
    if avg7 < 0:
        st.error("æœªæ¥çŸ­æœŸå‡€ç°é‡‘æµåå¼±ï¼Œå»ºè®®æå‰ç»Ÿç­¹èµ„é‡‘è°ƒåº¦ã€å‹é™æ”¯å‡ºå¹¶åŠ å¿«å›æ¬¾ã€‚")
    else:
        st.success("æœªæ¥çŸ­æœŸå‡€ç°é‡‘æµæ•´ä½“å¹³ç¨³åæ­£ï¼Œèµ„é‡‘å®‰å…¨è¾¹é™…è¾ƒä¸ºå……è¶³ï¼Œå¯ç¨³æ­¥æ¨è¿›æ—¢å®šç»è¥è®¡åˆ’ã€‚")

    # æ•°æ®é¢„è§ˆ
    st.subheader("ğŸ“ æ•°æ®é¢„è§ˆï¼ˆä¸­æ–‡è¡¨å¤´ï¼‰")
    preview = df[["date", "cash_in", "cash_out", "net_cash_flow"]].copy()
    preview.rename(columns=COLUMN_NAME_MAP, inplace=True)
    preview["æ—¥æœŸ"] = format_date_series(preview["æ—¥æœŸ"])
    st.dataframe(styled_table(preview), use_container_width=True)

    if not run_button:
        st.info("è¯·åœ¨å·¦ä¾§è®¾ç½®å‚æ•°åï¼Œç‚¹å‡»â€œå¼€å§‹è®­ç»ƒä¸é¢„æµ‹â€ã€‚")
        return

    # æ¨¡å‹è®­ç»ƒ
    target = "net_cash_flow"
    multi_features = [
        "net_cash_flow", "sales", "project_spend",
        "tax_payment", "cash_in", "cash_out"
    ]
    multi_features = [c for c in multi_features if c in df.columns]

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### ğŸ”¹ å•å˜é‡ LSTMï¼ˆä»…å‡€ç°é‡‘æµï¼‰")
        with st.spinner("æ­£åœ¨è®­ç»ƒå•å˜é‡æ¨¡å‹â€¦"):
            m1, fs1, ts1, X1, y1, hist1, eval1 = train_lstm_model(
                df, [target], target, window_size, epochs
            )
        st.write(f"MAEï¼š{eval1['mae']:.2f}")
        st.write(f"RMSEï¼š{eval1['rmse']:.2f}")
    with col2:
        st.markdown("### ğŸ”¸ å¤šç‰¹å¾ LSTMï¼ˆå‡€ç°é‡‘æµ + ä¸šåŠ¡ç‰¹å¾ï¼‰")
        with st.spinner("æ­£åœ¨è®­ç»ƒå¤šç‰¹å¾æ¨¡å‹â€¦"):
            m2, fs2, ts2, X2, y2, hist2, eval2 = train_lstm_model(
                df, multi_features, target, window_size, epochs
            )
        st.write(f"MAEï¼š{eval2['mae']:.2f}")
        st.write(f"RMSEï¼š{eval2['rmse']:.2f}")

    history = hist2.copy()

    # å¤šæ­¥é¢„æµ‹ + é›†æˆ + æƒ…æ™¯
    st.subheader("ğŸ”® ç°é‡‘æµé¢„æµ‹ï¼ˆé›†æˆæ¨¡å‹ + ç½®ä¿¡åŒºé—´ + æƒ…æ™¯ï¼‰")
    with st.spinner("æ­£åœ¨è¿›è¡Œå¤šæ­¥é¢„æµ‹ä¸ä¸ç¡®å®šæ€§ä¼°è®¡â€¦"):
        last1 = X1[-window_size:]
        last2 = X2[-window_size:]

        mean1, low1, high1 = mc_dropout_forecast_batch(
            m1, last1, ts1, forecast_days, n_samples
        )
        mean2, low2, high2 = mc_dropout_forecast_batch(
            m2, last2, ts2, forecast_days, n_samples
        )

        inv1 = 1 / (eval1["rmse"] + 1e-6)
        inv2 = 1 / (eval2["rmse"] + 1e-6)
        w1 = inv1 / (inv1 + inv2)
        w2 = inv2 / (inv2 + inv2) if (inv2 + inv2) != 0 else 0.5  # é˜²å¾¡æ€§å†™æ³•ï¼ˆä¸å¤ªå¯èƒ½ä¸º0ï¼‰

        last_date = history["date"].iloc[-1]
        future_dates = [last_date + timedelta(days=i + 1) for i in range(forecast_days)]

        base_mean = w1 * mean1 + w2 * mean2
        base_low = w1 * low1 + w2 * low2
        base_high = w1 * high1 + w2 * high2

        # æƒ…æ™¯ç³»æ•°
        if scenario == "ä¹è§‚":
            factor = 1.10
        elif scenario == "è°¨æ…":
            factor = 0.90
        else:
            factor = 1.00

        scenario_mean = base_mean * factor
        scenario_low = base_low * factor
        scenario_high = base_high * factor

        forecast_df = pd.DataFrame({
            "æ—¥æœŸ": format_date_series(pd.Series(future_dates)),
            "é¢„æµ‹å‡å€¼": scenario_mean,
            "ä¸‹ç•Œï¼ˆ95%ï¼‰": scenario_low,
            "ä¸Šç•Œï¼ˆ95%ï¼‰": scenario_high,
        })

    st.success(
        f"é¢„æµ‹å®Œæˆï¼å½“å‰æƒ…æ™¯ï¼š**{scenario}**ï¼›å•å˜é‡æƒé‡ {w1:.2f}ï¼Œå¤šç‰¹å¾æƒé‡ {w2:.2f}ã€‚"
    )

    # Plotly é¢„æµ‹å›¾
    fig = build_forecast_figure(history, forecast_df, scenario, viz_mode)
    st.plotly_chart(fig, use_container_width=True)

    # é¢„æµ‹ç»“æœè¡¨æ ¼ + ä¸‹è½½
    st.markdown("### ğŸ“„ é¢„æµ‹ç»“æœï¼ˆè¡¨æ ¼å±•ç¤ºï¼‰")
    st.dataframe(styled_table(forecast_df), use_container_width=True)

    download_df = forecast_df.copy()
    num_cols = ["é¢„æµ‹å‡å€¼", "ä¸‹ç•Œï¼ˆ95%ï¼‰", "ä¸Šç•Œï¼ˆ95%ï¼‰"]
    download_df[num_cols] = download_df[num_cols].round(2)
    csv_bytes = download_df.to_csv(index=False, encoding="utf-8-sig")
    st.download_button(
        "ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœï¼ˆCSVï¼Œä¸­æ–‡è¡¨å¤´ï¼Œå«æƒ…æ™¯ï¼‰",
        csv_bytes,
        file_name=f"ç°é‡‘æµé¢„æµ‹ç»“æœ_{scenario}æƒ…æ™¯.csv",
        mime="text/csv",
    )

    # èµ„é‡‘ç¼ºå£é¢„è­¦ä¸å¸åº“è°ƒåº¦å»ºè®®ï¼ˆç®€å•çº¢çº¿è§„åˆ™ï¼‰
    st.subheader("ğŸš¨ èµ„é‡‘ç¼ºå£é¢„è­¦ä¸å¸åº“è°ƒåº¦å»ºè®®")

    horizon = min(30, len(forecast_df))
    future_window = forecast_df.head(horizon).copy()
    negatives = future_window["é¢„æµ‹å‡å€¼"] < 0

    if not negatives.any():
        st.success(
            "æœªæ¥30æ—¥é¢„æµ‹å‡€ç°é‡‘æµæ•´ä½“ä¸ºæ­£ï¼Œæš‚æœªè§¦å‘èµ„é‡‘ç¼ºå£é¢„è­¦ï¼Œå¯æŒ‰æ—¢å®šè®¡åˆ’ç¨³å¥æ¨è¿›ã€‚"
        )
        st.markdown(
            "- å»ºè®®ç»§ç»­å…³æ³¨å¤§é¢é¡¹ç›®æ”¯å‡ºä¸å›æ¬¾èŠ‚å¥ï¼Œä¿æŒä¸é“¶è¡Œæˆä¿¡æ–¹çš„æ²Ÿé€šç•…é€šï¼›  \n"
            "- å¯é€‚åº¦è¿ç”¨çŸ­æœŸç†è´¢æˆ–ç»“æ„æ€§å­˜æ¬¾ï¼Œæé«˜é—²ç½®èµ„é‡‘æ”¶ç›Šã€‚"
        )
    else:
        max_streak = 0
        cur_streak = 0
        for is_neg in negatives:
            if is_neg:
                cur_streak += 1
                max_streak = max(max_streak, cur_streak)
            else:
                cur_streak = 0

        first_neg_date = future_window.loc[negatives, "æ—¥æœŸ"].iloc[0]

        if max_streak >= 3:
            st.error(
                f"æœªæ¥30æ—¥å†…å­˜åœ¨è¿ç»­ {max_streak} å¤©å‡€ç°é‡‘æµä¸ºè´Ÿï¼Œ"
                f"é¦–æ¬¡å‡ºç°ç¼ºå£æ—¥æœŸçº¦ä¸ºï¼š{first_neg_date}ï¼Œéœ€ç«‹å³å¯åŠ¨èµ„é‡‘é¢„æ¡ˆã€‚"
            )
            st.markdown(
                "- å»ºè®®ç«‹å³æ¢³ç†åœ¨æ‰‹è´§å¸èµ„é‡‘ã€æœªä½¿ç”¨æˆä¿¡é¢åº¦å’Œå†…éƒ¨èµ„é‡‘æ± å¯è°ƒåº¦ç©ºé—´ï¼›  \n"
                "- å¯¹å¤§é¢èµ„æœ¬æ€§æ”¯å‡ºã€ä½æ”¶ç›Šé¡¹ç›®æ”¯å‡ºè¿›è¡ŒèŠ‚å¥é‡æ’æˆ–æš‚ç¼“ï¼›  \n"
                "- æå‰ä¸ä¸»è¦å¾€æ¥é“¶è¡Œæ²Ÿé€šï¼Œé”å®šçŸ­æœŸæµåŠ¨æ€§æ”¯æŒæ–¹æ¡ˆï¼ˆå¦‚æµåŠ¨èµ„é‡‘è´·æ¬¾ã€é“¶ç¥¨æ± ç­‰ï¼‰ï¼›  \n"
                "- å¼ºåŒ–åº”æ”¶è´¦æ¬¾å‚¬æ”¶å’Œä¿ç†ç­‰å·¥å…·è¿ç”¨ï¼Œç¼©çŸ­èµ„é‡‘å›ç¬¼å‘¨æœŸã€‚"
            )
        else:
            st.warning(
                f"æœªæ¥30æ—¥å†…éƒ¨åˆ†æ—¥æœŸå‡€ç°é‡‘æµä¸ºè´Ÿï¼Œé¦–æ¬¡å‡ºç°ç¼ºå£æ—¥æœŸçº¦ä¸ºï¼š{first_neg_date}ï¼Œ"
                "å»ºè®®æå‰ç»Ÿç­¹å®‰æ’ã€‚"
            )
            st.markdown(
                "- å»ºè®®å¯¹ç¼ºå£æ—¶ç‚¹å‰åçš„èµ„é‡‘æ”¶æ”¯è¿›è¡Œç²¾ç»†åŒ–æ’æœŸï¼Œé¿å…é›†ä¸­æ”¯å‡ºå åŠ ï¼›  \n"
                "- é€šè¿‡åº”æ”¶è´¦æ¬¾ç›˜ç‚¹ã€åŠ å¿«å¼€ç¥¨åŠå›æ¬¾ã€å†…éƒ¨å•ä½äº’è°ƒç­‰æ–¹å¼ï¼Œå¢å¼ºçŸ­æœŸæµåŠ¨æ€§ï¼›  \n"
                "- ç»“åˆé¢„æµ‹ç»“æœï¼Œå¿…è¦æ—¶å¯é¢„å…ˆé”å®šéƒ¨åˆ†é“¶è¡Œæˆä¿¡å¤‡ç”¨é¢åº¦ï¼Œä»¥é˜²å¤–éƒ¨ç¯å¢ƒçªå˜ã€‚"
            )

    # å¼‚å¸¸æ£€æµ‹
    st.subheader("âš  å†å²å‡€ç°é‡‘æµå¼‚å¸¸æ£€æµ‹ï¼ˆIQR + Z-scoreï¼‰")
    anomalies_raw = detect_anomalies_combined(history["date"], history[target])
    anomalies_cn = anomalies_to_chinese(anomalies_raw)
    if anomalies_cn.empty:
        st.info("æœªæ£€æµ‹åˆ°æ˜¾è‘—å¼‚å¸¸ç‚¹ã€‚")
    else:
        st.dataframe(styled_table(anomalies_cn), use_container_width=True)

    # æ•æ„Ÿæ€§åˆ†æ
    st.subheader("ğŸ” ç‰¹å¾æ•æ„Ÿæ€§åˆ†æï¼ˆä¸­æ–‡ï¼‰")
    if multi_features:
        sens_raw = feature_sensitivity_last_window(
            m2, X2[-window_size:], multi_features, ts2
        )
        sens_cn = sensitivity_to_chinese(sens_raw)
        st.dataframe(styled_table(sens_cn), use_container_width=True)
    else:
        st.info("å½“å‰æ•°æ®ç¼ºå°‘ä¸šåŠ¡ç‰¹å¾åˆ—ï¼Œæ— æ³•è¿›è¡Œæ•æ„Ÿæ€§åˆ†æã€‚")


if __name__ == "__main__":
    main()
